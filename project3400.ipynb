{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb111671",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b64cc657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler, FunctionTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba21ee2c",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a3f1d88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  \n",
       "2     10.1        6  \n",
       "3      9.9        6  \n",
       "4      9.9        6  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the data\n",
    "df = pd.read_csv(r\"C:\\Users\\mahey\\Downloads\\wine-data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "618f02ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6463 entries, 0 to 6462\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         6463 non-null   float64\n",
      " 1   volatile acidity      6463 non-null   float64\n",
      " 2   citric acid           6463 non-null   float64\n",
      " 3   residual sugar        6463 non-null   float64\n",
      " 4   chlorides             6463 non-null   float64\n",
      " 5   free sulfur dioxide   6463 non-null   float64\n",
      " 6   total sulfur dioxide  6463 non-null   float64\n",
      " 7   density               6463 non-null   float64\n",
      " 8   pH                    6463 non-null   float64\n",
      " 9   sulphates             6463 non-null   float64\n",
      " 10  alcohol               6463 non-null   float64\n",
      " 11  quality               6463 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 606.0 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fixed acidity           0\n",
       "volatile acidity        0\n",
       "citric acid             0\n",
       "residual sugar          0\n",
       "chlorides               0\n",
       "free sulfur dioxide     0\n",
       "total sulfur dioxide    0\n",
       "density                 0\n",
       "pH                      0\n",
       "sulphates               0\n",
       "alcohol                 0\n",
       "quality                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying dataset information\n",
    "df.info()\n",
    "\n",
    "# Checking for null values in the dataset\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653ba103",
   "metadata": {},
   "source": [
    "# Initial Model Building and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "93e54d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottom-line Accuracy: 0.5382830626450116\n"
     ]
    }
   ],
   "source": [
    "# Preparing the feature matrix (X) and target vector (y)\n",
    "X = df.drop('quality', axis=1)  # Drop the target variable to create feature matrix\n",
    "y = df['quality']  # Target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the initial Logistic Regression model\n",
    "initial_model = LogisticRegression(max_iter=10000)\n",
    "initial_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and calculate accuracy\n",
    "initial_predictions = initial_model.predict(X_test)\n",
    "bottom_line_accuracy = accuracy_score(y_test, initial_predictions)\n",
    "\n",
    "print(f\"Bottom-line Accuracy: {bottom_line_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fa0216",
   "metadata": {},
   "source": [
    "# Feature Transformations and Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "09f10571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min-max_model Accuracy: 0.5320959010054138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mahey\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "df_scaled = X.copy()\n",
    "col_names = ['free sulfur dioxide']\n",
    "features = df_scaled[col_names]\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled[col_names] = scaler.fit_transform(features.values)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the initial Logistic Regression model\n",
    "min_model = LogisticRegression(max_iter=10000)\n",
    "min_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and calculate accuracy\n",
    "initial_predictions = min_model.predict(X_test)\n",
    "bottom_line_accuracy = accuracy_score(y_test, initial_predictions)\n",
    "\n",
    "print(f\"min-max_model Accuracy: {bottom_line_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b88814b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Scaler Accuracy: 0.5390564578499614\n"
     ]
    }
   ],
   "source": [
    "df_scaled = X.copy()\n",
    "\n",
    "# Scaling the 'alcohol' feature using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_scaled['alcohol'] = scaler.fit_transform(df_scaled[['alcohol']])\n",
    "\n",
    "# Splitting the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Building the Logistic Regression model with increased number of iterations\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions and calculating accuracy\n",
    "predictions = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Printing the accuracy\n",
    "print(f\"Standard Scaler Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "106811ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxAbsScaler Accuracy: 0.5375096674400619\n"
     ]
    }
   ],
   "source": [
    "df_scaled = X.copy()\n",
    "\n",
    "# Scaling the 'total sulfur dioxide' feature using MaxAbsScaler\n",
    "scaler = MaxAbsScaler()\n",
    "df_scaled['total sulfur dioxide'] = scaler.fit_transform(df_scaled[['total sulfur dioxide']])\n",
    "\n",
    "# Splitting the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Building the Logistic Regression model with increased number of iterations\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions and calculating accuracy\n",
    "predictions = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Printing the accuracy\n",
    "print(f\"MaxAbsScaler Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0b12eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobustScaler Accuracy: 0.5367362722351121\n"
     ]
    }
   ],
   "source": [
    "df_scaled = X.copy()\n",
    "\n",
    "# Scaling the 'total sulfur dioxide' feature using RobustScaler\n",
    "scaler = RobustScaler()\n",
    "df_scaled['total sulfur dioxide'] = scaler.fit_transform(df_scaled[['total sulfur dioxide']])\n",
    "\n",
    "# Splitting the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Building the Logistic Regression model with increased number of iterations\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions and calculating accuracy\n",
    "predictions = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Printing the accuracy with the correct label\n",
    "print(f\"RobustScaler Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6a79d68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Scaler Accuracy: 0.5328692962103635\n"
     ]
    }
   ],
   "source": [
    "# df_scaled = X.copy()\n",
    "col_names = ['total sulfur dioxide']\n",
    "features = df_scaled[col_names]\n",
    "scaler = StandardScaler()\n",
    "df_scaled[col_names] = scaler.fit_transform(features.values)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the initial Logistic Regression model\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and calculate accuracy\n",
    "initial_predictions = model.predict(X_test)\n",
    "bottom_line_accuracy = accuracy_score(y_test, initial_predictions)\n",
    "\n",
    "print(f\"Standard Scaler Accuracy: {bottom_line_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81d7c2c",
   "metadata": {},
   "source": [
    "# Feature Selection and Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6b30288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_selection_model_1 Accuracy: 0.5204949729311679\n"
     ]
    }
   ],
   "source": [
    "feature_selection_model=X.copy()\n",
    "feature_selection_model = feature_selection_model.drop(feature_selection_model.columns[[0,1,2,3,4,5,6,7]], axis=1)\n",
    "feature_selection_model.head()\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_selection_model, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the initial Logistic Regression model\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and calculate accuracy\n",
    "initial_predictions = model.predict(X_test)\n",
    "bottom_line_accuracy = accuracy_score(y_test, initial_predictions)\n",
    "\n",
    "print(f\"feature_selection_model_1 Accuracy: {bottom_line_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7f824aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_selection_model_2 Accuracy: 0.44934261407579273\n"
     ]
    }
   ],
   "source": [
    "feature_selection_model=X.copy()\n",
    "feature_selection_model = feature_selection_model.drop(feature_selection_model.columns[[3,4,5,6,7,8,9,10]], axis=1)\n",
    "feature_selection_model.head()\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_selection_model, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the initial Logistic Regression model\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and calculate accuracy\n",
    "initial_predictions = model.predict(X_test)\n",
    "bottom_line_accuracy = accuracy_score(y_test, initial_predictions)\n",
    "\n",
    "print(f\"feature_selection_model_2 Accuracy: {bottom_line_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f2d3029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_selection_model_3 Accuracy: 0.4508894044856922\n"
     ]
    }
   ],
   "source": [
    "feature_selection_model=X.copy()\n",
    "feature_selection_model = feature_selection_model.drop(feature_selection_model.columns[[0,3,4,5,6,7,9,10]], axis=1)\n",
    "feature_selection_model.head()\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_selection_model, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the initial Logistic Regression model\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and calculate accuracy\n",
    "initial_predictions = model.predict(X_test)\n",
    "bottom_line_accuracy = accuracy_score(y_test, initial_predictions)\n",
    "\n",
    "print(f\"feature_selection_model_3 Accuracy: {bottom_line_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31d43e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_selection_model_4 Accuracy: 0.5150812064965197\n"
     ]
    }
   ],
   "source": [
    "feature_selection_model=X.copy()\n",
    "feature_selection_model = feature_selection_model.drop(feature_selection_model.columns[[0,1,2,4,5,7,8,9]], axis=1)\n",
    "feature_selection_model.head()\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_selection_model, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the initial Logistic Regression model\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and calculate accuracy\n",
    "initial_predictions = model.predict(X_test)\n",
    "bottom_line_accuracy = accuracy_score(y_test, initial_predictions)\n",
    "\n",
    "print(f\"feature_selection_model_4 Accuracy: {bottom_line_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab168a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_selection_model_5 Accuracy: 0.5104408352668214\n"
     ]
    }
   ],
   "source": [
    "feature_selection_model=X.copy()\n",
    "feature_selection_model = feature_selection_model.drop(feature_selection_model.columns[[0,1,2,4,5,6,7,9]], axis=1)\n",
    "feature_selection_model.head()\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_selection_model, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the initial Logistic Regression model\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and calculate accuracy\n",
    "initial_predictions = model.predict(X_test)\n",
    "bottom_line_accuracy = accuracy_score(y_test, initial_predictions)\n",
    "\n",
    "print(f\"feature_selection_model_5 Accuracy: {bottom_line_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915d10c5",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82e3d19",
   "metadata": {},
   "source": [
    "Overview of Model Performances:\n",
    "Bottom-line Model:\n",
    "\n",
    "The bottom-line model, which uses the original dataset without any modifications, achieved an accuracy of 0.5383. This serves as our baseline for comparison.\n",
    "\n",
    "Data Transformation Models:\n",
    "\n",
    "The models using Standard Scaler, MaxAbsScaler, RobustScaler, and MinMaxScaler showed accuracies ranging from 0.5321 to 0.5391. Notably, the Standard Scaler applied to a different feature achieved the highest accuracy among these (0.5391), slightly surpassing the bottom-line model. This suggests that standardization may offer a marginal benefit over the original data scaling for this specific dataset.\n",
    "The other scaling techniques (MaxAbsScaler, RobustScaler, and MinMaxScaler) resulted in accuracies marginally lower than the bottom-line model, indicating a negligible or no substantial improvement over the untransformed data.\n",
    "\n",
    "Feature Selection Models:\n",
    "\n",
    "The feature selection models showed a decrease in accuracy compared to the bottom-line model, with accuracies ranging from 0.4493 to 0.5205.\n",
    "The most significant drop in accuracy was observed in feature_selection_model_2 (0.4493), suggesting that the features removed in this model were likely critical for predicting wine quality.\n",
    "The highest accuracy in feature selection models was feature_selection_model_1 (0.5205), which, while lower than the bottom-line accuracy, implies that certain features might have a more significant impact on the prediction outcome than others.\n",
    "\n",
    "Conclusions and Insights:\n",
    "\n",
    "Data Transformation Impact: The minimal impact of scaling techniques on model accuracy indicates that the original feature scales in this dataset are already quite suitable for logistic regression modeling. The slight improvement with Standard Scaler suggests that some features might benefit from normalization, but the overall benefit is limited.\n",
    "\n",
    "Feature Selection Impact: The general decrease in accuracy with feature selection models emphasizes the importance of the features in predicting wine quality. Removing even a small number of features can lead to significant information loss, negatively affecting the model's performance.\n",
    "\n",
    "Optimal Data Preparation Strategy: For this dataset, using all features with minimal transformation seems to be the most effective strategy. While certain scaling methods offer a marginal increase in accuracy, the overall benefit compared to the computational cost and complexity is limited"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
